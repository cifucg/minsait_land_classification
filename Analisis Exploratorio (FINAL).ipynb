{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=4>UniversityHack2020</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>Reto Minsait Land Classification</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Cristian Cifuentes García, Manuel Bermúdez Martínez</font><br>\n",
    "<font color=\"#004D7F\" size=3>Curso de Especialista en Ciencia de Datos y Desarrollo de Aplicaciones en la Nube </font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad de Castilla-La Mancha</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Requisitos](#section2)\n",
    "* [3. Análisis exploratorio de los datos](#section3)\n",
    "    * [3.1 Tratamiento de las columnas numéricas](#section31)\n",
    "    * [3.1 Tratamiento de las columnas discretas](#section32)\n",
    "* [4. Procesamiento del conjunto de datos](#section4)\n",
    "<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Utiliza la información de las imágenes de satélite para clasificar el suelo.</center></h3>\n",
    "\n",
    "Actualmente, un gran número de satélites toman imágenes con distintos fines y usos. El gran número de imágenes y la gran cantidad de datos que se obtienen de las mismas hace necesario crear modelos predictivos para identificar el contenido de la imagen.\n",
    "\n",
    "En este reto ya dispondrás de las variables extraídas de la imagen y georeferenciadas, así como variables categóricas asociadas al entorno para estimar un modelo.\n",
    "\n",
    "<h3><center>El Objetivo</center></h3>\n",
    "\n",
    "Te retamos a que encuentres el mejor modelo de clasificación automática de suelos en base a las imágenes proporcionadas por el satélite Sentinel II del servicio Copernicus de la Agencia Espacial Europea.\n",
    "\n",
    "En este reto dispondrás de un conjunto de fincas catastrales asociados a una lista de atributos extraídos de la imagen.\n",
    "\n",
    "Para ello puedes utilizar las distintas técnicas de Machine Learning disponibles para este tipo de problemas.\n",
    "\n",
    "La métrica objetivo a maximizar es la “Exactitud”, (en R, en Python) definida como el “Número de registros correctamente clasificados / Número total de registros proporcionados por la Organización”.\n",
    "\n",
    "<img src=\"data/mapa_introduccion.jpg\">\n",
    "\n",
    "<h3><center>El Dataset</center></h3>\n",
    "\n",
    "El dataset contiene un listado de superficies sobre las que se han recortado la imagen de satélite y se han extraído una serie de características de sus geometrías. Finalmente se ha etiquetado el conjunto de los datos según una clasificación de suelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#004D7F\"> 2. Requisitos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta celda está destinada a la importación de los paquetes y librerías necesarias para el desarrollo del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "sns.set()\n",
    "\n",
    "# Permite que las graficas se generen a mayor resolucion\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Establece un ancho de libreta mayor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "from ipywidgets import interact \n",
    "\n",
    "# Librerias necesarias para el aprendizaje de modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos proporcionado en un fichero de texto plano y lo convertimos en un *dataframe* de *pandas*. Este operación tiene la finalidad de permitirnos trabajar de forma más rápida y eficiente con el conjunto de datos y así, poder realizar un buen análisis exploratorio del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar = pd.read_csv('data/Modelar_UH2020.txt', sep=\"|\", index_col='ID', encoding='utf-8')\n",
    "print(\"Tamaño del conjunto de datos:  %d\" % df_modelar.shape[0])\n",
    "print(\"Número de variables: %d\" % df_modelar.shape[1])\n",
    "if df_modelar.index.is_unique:\n",
    "    print('El índice es único.')\n",
    "else:\n",
    "    print('Los índices están duplicados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que contamos con un total de <b>103230 datos</b>, es decir, con una gran cantidad de registros. Este elevado número nos puede ayudar, en gran parte, a desarrollar un modelo con un rendimiento acertado. Por otro lado, contamos con <b>56 variables</b>, pero se ha establecido como índice del conjunto de datos la variable *ID*, tras comprobar que realmente es un identificador único y no se repite, por lo cual, <b>el número de variables disminuye a 55.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_class_order = ['RESIDENTIAL', 'PUBLIC', 'RETAIL', 'OFFICE', 'INDUSTRIAL', 'AGRICULTURE', 'OTHER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta lista tiene la finalidad de obtener el mismo color en todas las gráficas y representar la variable objetivo siempre en el mismo orden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#004D7F\"> 3. Análisis exploratorio de los datos</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una primera toma de contacto con los datos, podemos ver una pequeña parte del conjunto para ver qué valores toman cada una de las 55 variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables y el tipo de datos de cada una de ellas es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve a simple vista que predominan las variables numéricas y que el conjunto de datos presenta muy pocas variables discretas. De todas formas, realizaremos un tratamiento específico para cada una de ellas en el apartado correspondiente. \n",
    "\n",
    "Hay que tener en cuenta que el principal problema de este reto es el desbalanceo de las clases y por ello mismo, se debe de comprobar cuantos registros tenemos para cada uno de los diferentes valores de la variables a objetivo o a predecir, que es la variable `Clase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='CLASE', data=df_modelar)\n",
    "plt.title('Distribución de muestras')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la gráfica se puede observar que nos encontramos ante un conjunto de datos muy desbalanceado, ya que el mayor porcentaje de datos corresponde a la clase <b>*Residential*</b> y existe una gran diferencia con el resto de clases del conjunto de datos. De hecho, si nos fijamos a continuación podemos ver el porcentaje que representa cada una de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_modelar['CLASE'].unique().tolist():\n",
    "    total = df_modelar[df_modelar['CLASE']==item]['CLASE'].value_counts().values[0]\n",
    "    print(f\"El porcentaje de muestras de {item} es {(sum(df_modelar['CLASE']==item) / df_modelar.shape[0]):.3f}% con un total de: {total} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo de estos datos, es necesario realizar un profundo análisis de todas columnas de nuestro conjunto de datos, ya que el número total de registros es muy elevado, así como el número de características que presenta el dataset. Para ello, nos centraremos en dividir estas características en función del tipo de dato que representen, como hemos podido observar anteriormente.\n",
    "\n",
    "En la siguiente celda realizamos esta división, es decir, dividimos las variables en dos listas dependiendo del tipo de dato que representen. Además, en las variables discretas eliminamos la variable `Clase` ya que se trata de la variable objetivo y por el momento no se va a realizar ningún preprocesamiento en ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df_columns = df_modelar.select_dtypes(exclude=np.number).columns.tolist()\n",
    "dis_df_columns.remove('CLASE') #Eliminamos la variable clase\n",
    "number_df_columns = df_modelar.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print('Variables discretas: ',dis_df_columns)\n",
    "print('\\nVariables numéricas: ',number_df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos hecha la división de forma correcta, debemos de realizar un el tratamiento de forma independiente y así, comprobar si realmente pertenecen al tipo de datos que representa la variable o se pueden convertir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "### <font color=\"#004D7F\">3.1 Tratamiento de las columnas numéricas </font>\n",
    "\n",
    "El tratamiento de las columnas numéricas es relativamente sencillo, y se puede descomponer en varias etapas:\n",
    "\n",
    "* Comprobar que, efectivamente, corresponden a características numéricas. \n",
    "* Detección y tratamiento de outliers. \n",
    "* Detección y tratemiento de valores perdidos. \n",
    "* Exploración de las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se comprueba es su realmente estas variables son numéricas o se pueden convertir a discretas, por ejemplo, si una variable tiene unicamente tres valores se convertirá en una variable discreta en vez de numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_df_values = [(col, len(df_modelar[col].value_counts())) for col in number_df_columns]\n",
    "num_df_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que parece, todas las variables ellas son numéricas y no se debe de realizar ningun cambio para ellas. Al tener un alto número de variables vamos a realizar subdivisiones en función de la identificación de cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Colores:** 'Q_R_4_0_0', 'Q_R_4_0_1', 'Q_R_4_0_2', 'Q_R_4_0_3', 'Q_R_4_0_4', 'Q_R_4_0_5', 'Q_R_4_0_6', 'Q_R_4_0_7', 'Q_R_4_0_8', 'Q_R_4_0_9', 'Q_R_4_1_0', 'Q_G_3_0_0', 'Q_G_3_0_1', 'Q_G_3_0_2', 'Q_G_3_0_3', 'Q_G_3_0_4', 'Q_G_3_0_5', 'Q_G_3_0_6', 'Q_G_3_0_7', 'Q_G_3_0_8', 'Q_G_3_0_9', 'Q_G_3_1_0', 'Q_B_2_0_0', 'Q_B_2_0_1', 'Q_B_2_0_2', 'Q_B_2_0_3', 'Q_B_2_0_4', 'Q_B_2_0_5', 'Q_B_2_0_6', 'Q_B_2_0_7', 'Q_B_2_0_8', 'Q_B_2_0_9', 'Q_B_2_1_0', 'Q_NIR_8_0_0', 'Q_NIR_8_0_1', 'Q_NIR_8_0_2', 'Q_NIR_8_0_3', 'Q_NIR_8_0_4', 'Q_NIR_8_0_5', 'Q_NIR_8_0_6', 'Q_NIR_8_0_7', 'Q_NIR_8_0_8', 'Q_NIR_8_0_9', 'Q_NIR_8_1_0'\n",
    "- **Geométricas:** 'AREA', 'GEOM_R1', 'GEOM_R2', 'GEOM_R3', 'GEOM_R4'\n",
    "- **Otras:** 'CONTRUCTIONYEAR', 'MAXBUILDINGFLOOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = ['X', 'Y']\n",
    "colors = ['Q_R_4_0_0', 'Q_R_4_0_1', 'Q_R_4_0_2', 'Q_R_4_0_3', 'Q_R_4_0_4', 'Q_R_4_0_5', 'Q_R_4_0_6', 'Q_R_4_0_7',\n",
    "          'Q_R_4_0_8', 'Q_R_4_0_9', 'Q_R_4_1_0', 'Q_G_3_0_0', 'Q_G_3_0_1', 'Q_G_3_0_2', 'Q_G_3_0_3', 'Q_G_3_0_4',\n",
    "          'Q_G_3_0_5', 'Q_G_3_0_6', 'Q_G_3_0_7', 'Q_G_3_0_8', 'Q_G_3_0_9', 'Q_G_3_1_0', 'Q_B_2_0_0', 'Q_B_2_0_1',\n",
    "          'Q_B_2_0_2', 'Q_B_2_0_3', 'Q_B_2_0_4', 'Q_B_2_0_5', 'Q_B_2_0_6', 'Q_B_2_0_7', 'Q_B_2_0_8', 'Q_B_2_0_9',\n",
    "          'Q_B_2_1_0', 'Q_NIR_8_0_0', 'Q_NIR_8_0_1', 'Q_NIR_8_0_2', 'Q_NIR_8_0_3', 'Q_NIR_8_0_4', 'Q_NIR_8_0_5', \n",
    "          'Q_NIR_8_0_6', 'Q_NIR_8_0_7', 'Q_NIR_8_0_8', 'Q_NIR_8_0_9', 'Q_NIR_8_1_0']\n",
    "geom = ['AREA', 'GEOM_R1', 'GEOM_R2', 'GEOM_R3', 'GEOM_R4']\n",
    "others = ['CONTRUCTIONYEAR', 'MAXBUILDINGFLOOR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"#004D7F\"> Variables realtivas a las posiciones </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información de longitud-latitud ha sido escalada y desplazada aleatoriamente (manteniendo la relación de posición con el resto de puntos). Aún así vamos a intentar dibujar los puntos que tenemos en el conjunto de datos con respecto a la latitud y la longitud para hacernos una idea de las parcelas y de la clase que presentan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos. En este caso no presenta valores perdidos y por lo tanto no es realizar ningun tipo de análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[position].isna().sum()[df_modelar[position].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "sns.scatterplot(x=\"X\", y=\"Y\", hue=\"CLASE\",data=df_modelar)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a analizar cada una de las distribuiciones de las clases en función a sus posiciones geográficas, para ver que información nos pueden trasmitir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"X\", y=\"Y\", col=\"CLASE\", hue=\"CLASE\", kind=\"scatter\", col_wrap=3, data=df_modelar);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar en ambas gráficas que, aunque estos datos estén falseados, nos podemos hacer una pequeña idea de la situación de cada uno de los registros en función de la clase con la cual han sido clasificados. Por ejemplo, podemos observar que los registros pertenecientes a la clase de `Agricultura` se encuentran a las *afueras*, mientras que el resto de registros están mas céntricos.\n",
    "\n",
    "Por otro lado se pueden ver pequeñas zonas o agrupaciones de registros, que probablemente con algun tipo de modelo de clasificación mediante *clusters* se clasificarían correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"#004D7F\"> Variables realtivas a los colores </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/sentinel_resolution.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos. En este caso no presenta valores perdidos y por lo tanto no es realizar ningun tipo de análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[colors].isna().sum()[df_modelar[colors].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar[colors].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estudiar la correlación de todas y cada una de las variables relacionadas con el color es inviable y no se observarían correctamente los datos, lo que haremos es un agrupamiento por colores, es decir, tendremos lo siguiente:\n",
    "\n",
    "- **Rojo**\n",
    "- **Verde**\n",
    "- **Azul**\n",
    "- **NIR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color rojo\n",
    "df_modelar[colors[:11]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el color rojo podemos observar que existe una gran correlación entre casi todas las variables, excepto con las pertenecientes al decil 0 y 10. Por otro lado se puede observar que cada una de ellas presenta una mayor correlación con su respectivo antecesor y sucesor. Por ejemplo, la variable *Q_R_4_0_5* presenta una mayor correlación con *Q_R_4_0_4* y *Q_R_4_0_6*\n",
    "\n",
    "Como excepción, decir que el decil 9 (*Q_R_4_0_9*) presenta una mayor correlación con sus dos antecesores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color verde\n",
    "df_modelar[colors[11:22]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del color verde ocurre exactamente lo mismo que para el color rojo, ya que la máxima correlación la presentan con su decil anterior y posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color azul\n",
    "df_modelar[colors[22:33]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocurre lo mismo con el color azul y también para el NIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color azul\n",
    "df_modelar[colors[33:44]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de ver y comprobar la correlación que presentan este tipo de variables, también se ha realizado un pequeño análisis para comprender qué representan realmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = df_modelar[df_modelar.columns[2:-42]]\n",
    "df_green = df_modelar[df_modelar.columns[13:-31]]\n",
    "df_blue = df_modelar[df_modelar.columns[24:-20]]\n",
    "df_nir = df_modelar[df_modelar.columns[35:-9]]\n",
    "\n",
    "df_sum = df_red.sum(axis=1) + df_green.sum(axis=1) + df_blue.sum(axis=1) + df_nir.sum(axis=1)\n",
    "df_sum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colors = [df_modelar.columns[2:13], df_modelar.columns[13:24], df_modelar.columns[24:35], df_modelar.columns[35:46]]\n",
    "colors = [ 'red', 'green', 'blue', 'gray']\n",
    "for idx, val in enumerate(list_colors):\n",
    "    plt.figure(idx, figsize=(16,2))\n",
    "    sns.barplot(x=df_modelar.iloc[1][val].index, y=df_modelar.iloc[1][val].values, color=colors[idx], label=colors[idx])\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta gráfica podemos ver que los valores van creciendo progresivamente en función del decil en el cual se encuentran, por lo que descartamos que se trate de un histograma. Además, en el caso de ser un histograma, el valor total de la suma de las diferentes variables correspondientes a los colores debería de ser igual para cada uno de los distintos registros, ya que han sido extraidos de una misma imagen del satélite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"#004D7F\"> Variables relativas a la geometría </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos. En este caso no presenta valores perdidos y por lo tanto no es realizar ningun tipo de análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar[geom].isna().sum()[df_modelar[geom].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[geom].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos observar que existe una gran diferencia y que los valores máximos y mínimos se alejan enormemente de los rangos, como también se observa en el siguiente diagrama de cajas. Por ello mismo, se ha decidido eliminar lo que actualmente se consideran outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for col, ax in enumerate(axs.flatten()):\n",
    "    col_name = geom[col]\n",
    "    sns.boxplot(x=df_modelar[col_name], ax=ax)\n",
    "    ax.set_title(col_name);    \n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la eliminación de outliers obtenemos el siguiente diagrama de cajas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_outliers_geom(df, columns):\n",
    "    df_aux = df.copy()\n",
    "    for col_name in columns:\n",
    "        if col_name == 'AREA':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.8)\n",
    "            df_aux = df_aux[df_aux[col_name] < third_quantile_area]\n",
    "        elif col_name == 'GEOM_R1':\n",
    "            first_quantile_area = df_aux[col_name].quantile(0.016)\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.92)\n",
    "            df_aux = df_aux[(df_aux[col_name] > first_quantile_area) & (df_aux[col_name] < third_quantile_area)]\n",
    "        elif col_name == 'GEOM_R2':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.96)\n",
    "            df_aux = df_aux[df_aux[col_name] < third_quantile_area]\n",
    "        elif col_name == 'GEOM_R3':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.96)\n",
    "            df_aux = df_aux[df_aux[col_name] < third_quantile_area]\n",
    "        elif col_name == 'GEOM_R4':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.93)\n",
    "            first_quantile_area = df_aux[col_name].quantile(0.005)\n",
    "            df_aux = df_aux[(df_aux[col_name] > first_quantile_area) & (df_aux[col_name] < third_quantile_area)]\n",
    "        \n",
    "    return df_aux\n",
    "df_aux = delete_outliers_geom(df_modelar, geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de aplicar una eliminación de los supuestos outliers obtenemos el siguiente diagrama de cajas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for col, ax in enumerate(axs.flatten()):\n",
    "    col_name = geom[col]\n",
    "    sns.boxplot(x=df_aux[col_name], ax=ax)\n",
    "    ax.set_title(col_name);    \n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset con outliers: {df_modelar.shape}\")\n",
    "print(f\"Dataset sin outliers: {df_aux.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='CLASE', data=df_modelar, order=list_class_order)\n",
    "plt.title('Distribución de muestras')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='CLASE', data=df_aux, order=list_class_order);\n",
    "plt.title('Distribución de muestras')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La eliminación de outliers reduce considerablemente el número de registros de nuestro conjunto de datos y es por ello por lo que debemos de valorar si se deben de eliminar o no estos outliers o si realmente se trata de outliers o no. \n",
    "\n",
    "Aún así, si comprobamos la correlación de este conjunto de variables, con y sin outliers podemos observar que el hecho de eliminar tantos registros nos mejora apenas la correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with_outliers = df_modelar.corr()[geom]\n",
    "with_outliers.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "without_outliers = df_aux.corr()[geom]\n",
    "without_outliers.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables geométricas parecen tener una gran importancia en nuestro conjunto de datos, por lo que es conveniente seguir realizando un análisis exahustivo de ellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del área media por cada una de las clases a predecir\n",
    "df_modelar.groupby('CLASE')['AREA'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "sns.barplot(x=df_modelar.groupby('CLASE')['AREA'].mean().index.values, y=df_modelar.groupby('CLASE')['AREA'].mean().values, order=list_class_order)\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Media del área')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico se puede observar como la variable `RESIDENTIAL` que es la mayoritaría en nuestro conjunto de datos, presenta un área media bastante pequeña en comparación con el elementos de la variable objetivo. Esto nos puede dar una idea del tamaño de cada uno de los terrenos clasificados como `RESIDENTIAL` y se puede comprobar que representan un menor tamaño que el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar.groupby('CONTRUCTIONYEAR')[['AREA']].mean().nlargest(10, 'AREA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "sns.lineplot(data=df_modelar.groupby('CONTRUCTIONYEAR')[['AREA']].mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta gráfica se aprecia un pequeño aumento de la media del área conforme avanzan los años y llegamos a la actualidad o al datos más reciente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"#004D7F\"> Otras variables </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos. En este caso si presenta valores perdidos y por lo tanto es conveniente realizar un análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar[others].isna().sum()[df_modelar[others].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora realizamos una comprobación del conjunto de datos completo podemos observar que hay otra variable discreta que también presenta valores perdidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar.isna().sum()[df_modelar.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[df_modelar.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en realidad estos 40 valores perdidos corresponden unicamente con 20 registros de nuestro conjunto de datos, ya que casualmente los valores perdidos se presentan de forma simultánea tanto en la variable `CONTRUCTIONYEAR` como `MAXBUILDINGFLOOR`. Dado los valores perdidos pertenecen a las clases más desbalanceadas de nuestro conjunto se debe de tomar la decisión de qué hacer con los valores perdidos. \n",
    "\n",
    "También se debe de tener en cuenta que la variable `CONTRUCTIONYEAR` tiene un orden que indica la calidad del terreno, por lo que no podríamos establecer cualquier valor. Esta decisión se resolverá más adelante.\n",
    "\n",
    "Como información adicional, se realiza una gráfica interactiva para visualizar el número de registros de cada clase en función del año de construcción de los edificios colindantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year_class(Year=2017):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.countplot(df_modelar[df_modelar['CONTRUCTIONYEAR']==Year]['CONTRUCTIONYEAR'], hue=df_modelar['CLASE'])\n",
    "    plt.ylabel('Number')\n",
    "    plt.show()\n",
    "    print(f'-----------Year {Year}---------')\n",
    "    print(df_modelar[df_modelar['CONTRUCTIONYEAR']==Year]['CLASE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_year_class,\n",
    "         Year = np.sort(df_modelar['CONTRUCTIONYEAR'].unique()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_year = df_modelar.groupby('CONTRUCTIONYEAR')['CLASE'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "df_group_year.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos centramos en aquellas clases que son menos predominantes, ya que como el problema está desbalanceado, la clase Residencial es predominante.\n",
    "En la siguiente gráfica observamos que entre los años 1925 y 2017 los edificios predominantes son aquellos que presentan la clase industrial y publica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df_group_year.columns.tolist()[0:-2]\n",
    "classes.append('RETAIL')\n",
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "df_group_year[classes].plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "### <font color=\"#004D7F\">3.2 Tratamiento de las columnas discretas </font>\n",
    "\n",
    "\n",
    "En relación a estas columnas, dos aspectos muy relevantes de cara a la construcción de un modelo con `scikit-learn` son: el número de valores que puede tomar cada una; y si existe una relación de orden entre estos valores. Estos factores determinan el tipo de transformación que se ha de hacer. Existen cuatro posibilidades:\n",
    "\n",
    "* Cuando la columna toma dos valores, se puede binarizar y convertir a numérica diréctamente. \n",
    "* Si el tamaño del conjunto de valores es mayor que dos, y no existe una relación de orden entre ellos, se aplica `One Hot Encoding` (se aplicará posteriormente en el `Pipeline` de transformaciones).\n",
    "* Si existe una relación de orden, los valores se transforman a numéricos, sustituyendo cada valor por su orden. \n",
    "* Si el conjunto de valores extremadamente grande se ha de explorar, ya que es muy posible que se trate de un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordar que la variable CLASE también es discreta pero se ha eliminado al ser la varible objetivo\n",
    "num_values_dis_df_col = [(col, len(df_modelar[col].value_counts())) for col in dis_df_columns]\n",
    "num_values_dis_df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta variable en concreto tenemos una información adicional y es que se trata de una variable categórica representativa de la calidad y que tiene un órden:\n",
    "\n",
    "<b>MAYOR a MENOR CALIDAD: A > B > C > 1 > 2 > 3 >...> 8 > 9</b>\n",
    "\n",
    "Por lo tanto, lo primero que debemos de hacer es establecer ese órden en estas variable en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ¿Tratamos aqui ya los valores perdidos o sigo poniendo nan?\n",
    "def process_cadastralquality(value):\n",
    "    dic = {'A': 11, 'B': 10, 'C': 9}\n",
    "    if value in dic:\n",
    "        return dic[value]\n",
    "    else:\n",
    "        try:\n",
    "            return 9 - int(value)\n",
    "        except ValueError:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar['CADASTRALQUALITYID'] = df_modelar['CADASTRALQUALITYID'].apply(process_cadastralquality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar['CADASTRALQUALITYID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=df_modelar['CADASTRALQUALITYID'], data=df_modelar, hue=\"CLASE\", dodge=False)\n",
    "plt.title('Distribución de muestras');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
