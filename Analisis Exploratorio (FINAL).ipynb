{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=4>UniversityHack2020</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>Reto Minsait Land Classification</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3><a href=\"https://www.linkedin.com/in/cifucg\">Cristian Cifuentes García</a>, Manuel Bermúdez Martínez</font><br>\n",
    "<font color=\"#004D7F\" size=3>Curso de Especialista en Ciencia de Datos y Desarrollo de Aplicaciones en la Nube </font><br>\n",
    "<font color=\"#004D7F\" size=3>Universidad de Castilla-La Mancha</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Requisitos](#section2)\n",
    "* [3. Análisis exploratorio de los datos](#section3)\n",
    "    * [3.1 Tratamiento de las columnas numéricas](#section31)\n",
    "        * [3.1.1 Variables relativas al Geoposicionamiento](#section311)\n",
    "        * [3.1.2 Variables relativas a los Colores](#section312)\n",
    "        * [3.1.3 Variables relativas a la Geometría](#section313)\n",
    "        * [3.1.4 Variables relativas al año de construcción y máximo de pisos de los edificios colindantes](#section314)\n",
    "    * [3.2 Tratamiento de las columnas discretas](#section32)\n",
    "* [4. Procesamiento del conjunto de datos](#section4)\n",
    "<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Utiliza la información de las imágenes de satélite para clasificar el suelo.</center></h3>\n",
    "\n",
    "Actualmente, un gran número de satélites toman imágenes con distintos fines y usos. El gran número de imágenes y la gran cantidad de datos que se obtienen de las mismas hace necesario crear modelos predictivos para identificar el contenido de la imagen.\n",
    "\n",
    "En este reto ya dispondrás de las variables extraídas de la imagen y georeferenciadas, así como variables categóricas asociadas al entorno para estimar un modelo.\n",
    "\n",
    "<h3><center>Objetivo</center></h3>\n",
    "\n",
    "Te retamos a que encuentres el mejor modelo de clasificación automática de suelos en base a las imágenes proporcionadas por el satélite Sentinel II del servicio Copernicus de la Agencia Espacial Europea.\n",
    "\n",
    "En este reto dispondrás de un conjunto de fincas catastrales asociados a una lista de atributos extraídos de la imagen.\n",
    "\n",
    "Para ello puedes utilizar las distintas técnicas de Machine Learning disponibles para este tipo de problemas.\n",
    "\n",
    "La métrica objetivo a maximizar es la “Exactitud”, (en R, en Python) definida como el “Número de registros correctamente clasificados / Número total de registros proporcionados por la Organización”.\n",
    "\n",
    "<img src=\"data/mapa_introduccion.jpg\">\n",
    "\n",
    "<h3><center>El Dataset</center></h3>\n",
    "\n",
    "El dataset contiene un listado de superficies sobre las que se han recortado la imagen de satélite y se han extraído una serie de características de sus geometrías. Finalmente se ha etiquetado el conjunto de los datos según una clasificación de suelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#004D7F\"> 2. Requisitos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta celda está destinada a la importación de los paquetes y librerías necesarias para el desarrollo del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para el tratamiento de los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerias para la graficación de los datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "sns.set()\n",
    "\n",
    "# Permite que las graficas se generen a mayor resolucion\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Permite ignorar los warnings de la libreta al generar algunos modelos\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Establece un ancho de libreta mayor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "# Libreria necesaria para los gráficos interactivos\n",
    "from ipywidgets import interact \n",
    "\n",
    "# Librerias necesarias para el aprendizaje de modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos proporcionado en un fichero de texto plano y lo convertimos en un *dataframe* de *pandas*. Este operación tiene la finalidad de permitirnos trabajar de una forma más rápida y eficiente con el conjunto de datos y así, poder realizar un buen análisis exploratorio del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar = pd.read_csv('data/Modelar_UH2020.txt', sep=\"|\", index_col='ID', encoding='utf-8')\n",
    "print(\"Tamaño del conjunto de datos:  %d\" % df_modelar.shape[0])\n",
    "print(\"Número de variables: %d\" % df_modelar.shape[1])\n",
    "if df_modelar.index.is_unique:\n",
    "    print('El índice es único.')\n",
    "else:\n",
    "    print('Los índices están duplicados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que contamos con un total de <b>103230 datos</b>, es decir, con una gran cantidad de registros. Este elevado número nos puede ayudar, en gran parte, a desarrollar un modelo con un rendimiento acertado. Por otro lado, contamos con <b>56 variables</b>, pero se ha establecido como índice del conjunto de datos la variable *ID*, tras comprobar que realmente es un identificador único y no se repite, por lo que, <b>el número de variables disminuye a 55.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_class_order = ['RESIDENTIAL', 'PUBLIC', 'RETAIL', 'OFFICE', 'INDUSTRIAL', 'AGRICULTURE', 'OTHER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta lista presenta como finalidad la representación de las variables en el mismo orden y con el mismo color asociado en todas aquellas gráficas que las utilicemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#004D7F\"> 3. Análisis exploratorio de los datos</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una primera toma de contacto con los datos, podemos ver una pequeña parte del conjunto para ver qué valores toman cada una de las 55 variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables y el tipo de datos de cada una de ellas es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve a simple vista que predominan las variables numéricas y que el conjunto de datos presenta muy pocas variables discretas. De todas formas, realizaremos un tratamiento específico para cada una de ellas en el apartado correspondiente. \n",
    "\n",
    "Hay que tener en cuenta que el principal problema de este reto es el desbalanceo de las clases y por ello mismo, se debe de comprobar cuantos registros tenemos para cada uno de los diferentes valores de la variables a objetivo o a predecir, que es la variable `Clase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='CLASE', data=df_modelar)\n",
    "plt.title('Distribución de muestras')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la gráfica se puede observar que nos encontramos ante un conjunto de datos muy desbalanceado, ya que el mayor porcentaje de datos corresponde a la clase <b>*Residential*</b> y existe una gran diferencia con el resto de clases del conjunto de datos. De hecho, si nos fijamos a continuación podemos ver el porcentaje que representa cada una de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_modelar['CLASE'].unique().tolist():\n",
    "    reg = sum(df_modelar['CLASE']==item)\n",
    "    print(f\"- \\033[1m{item}\\033[0m presenta un \\033[1m{(reg / df_modelar.shape[0]):.3f}\\033[0m% del total con: \\033[1m{reg}\\033[0m registros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo de estos datos, es necesario realizar un profundo análisis de todas columnas de nuestro conjunto de datos, ya que el número total de registros es muy elevado, así como el número de características que presenta el dataset. Para ello, nos centraremos en dividir estas características en función del tipo de dato que representen, como hemos podido observar anteriormente.\n",
    "\n",
    "En la siguiente celda realizamos esta división, es decir, dividimos las variables en dos listas dependiendo del tipo de dato que representen. Además, en las variables discretas eliminamos la variable `Clase` ya que se trata de la variable objetivo y por el momento no se va a realizar ningún preprocesamiento en ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df_columns = df_modelar.select_dtypes(exclude=np.number).columns.tolist()\n",
    "dis_df_columns.remove('CLASE') #Eliminamos la variable clase\n",
    "number_df_columns = df_modelar.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print('\\033[1mVariables discretas\\033[0m: ',dis_df_columns)\n",
    "print('\\n\\033[1mVariables numéricas\\033[0m: ',number_df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos hecha la división de forma correcta, debemos de realizar un el tratamiento de forma independiente y así, comprobar si realmente pertenecen al tipo de datos que representa la variable o se pueden convertir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "### <font color=\"#004D7F\">3.1 Tratamiento de las columnas numéricas </font>\n",
    "\n",
    "El tratamiento de las columnas numéricas es relativamente sencillo, y se puede descomponer en varias etapas:\n",
    "\n",
    "* Comprobar que, efectivamente, corresponden a características numéricas. \n",
    "* Detección y tratamiento de outliers. \n",
    "* Detección y tratamiento de valores perdidos. \n",
    "* Exploración de las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se comprueba es su realmente estas variables son numéricas o se pueden convertir a discretas, por ejemplo, si una variable tiene unicamente tres valores se convertirá en una variable discreta en vez de numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_df_values = [(col, len(df_modelar[col].value_counts())) for col in number_df_columns]\n",
    "num_df_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que parece, todas las variables ellas son numéricas y no se debe de realizar ningun cambio para ellas. Al tener un alto número de variables vamos a realizar subdivisiones en función de la identificación de cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Geoposición**: 'X', 'Y'\n",
    "- **Colores:** 'Q_R_4_0_0', 'Q_R_4_0_1', 'Q_R_4_0_2', 'Q_R_4_0_3', 'Q_R_4_0_4', 'Q_R_4_0_5', 'Q_R_4_0_6', 'Q_R_4_0_7', 'Q_R_4_0_8', 'Q_R_4_0_9', 'Q_R_4_1_0', 'Q_G_3_0_0', 'Q_G_3_0_1', 'Q_G_3_0_2', 'Q_G_3_0_3', 'Q_G_3_0_4', 'Q_G_3_0_5', 'Q_G_3_0_6', 'Q_G_3_0_7', 'Q_G_3_0_8', 'Q_G_3_0_9', 'Q_G_3_1_0', 'Q_B_2_0_0', 'Q_B_2_0_1', 'Q_B_2_0_2', 'Q_B_2_0_3', 'Q_B_2_0_4', 'Q_B_2_0_5', 'Q_B_2_0_6', 'Q_B_2_0_7', 'Q_B_2_0_8', 'Q_B_2_0_9', 'Q_B_2_1_0', 'Q_NIR_8_0_0', 'Q_NIR_8_0_1', 'Q_NIR_8_0_2', 'Q_NIR_8_0_3', 'Q_NIR_8_0_4', 'Q_NIR_8_0_5', 'Q_NIR_8_0_6', 'Q_NIR_8_0_7', 'Q_NIR_8_0_8', 'Q_NIR_8_0_9', 'Q_NIR_8_1_0'\n",
    "- **Geométricas:** 'AREA', 'GEOM_R1', 'GEOM_R2', 'GEOM_R3', 'GEOM_R4'\n",
    "- **Otras:** 'CONTRUCTIONYEAR', 'MAXBUILDINGFLOOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoposition = ['X', 'Y']\n",
    "colors = ['Q_R_4_0_0', 'Q_R_4_0_1', 'Q_R_4_0_2', 'Q_R_4_0_3', 'Q_R_4_0_4', 'Q_R_4_0_5', 'Q_R_4_0_6', 'Q_R_4_0_7',\n",
    "          'Q_R_4_0_8', 'Q_R_4_0_9', 'Q_R_4_1_0', 'Q_G_3_0_0', 'Q_G_3_0_1', 'Q_G_3_0_2', 'Q_G_3_0_3', 'Q_G_3_0_4',\n",
    "          'Q_G_3_0_5', 'Q_G_3_0_6', 'Q_G_3_0_7', 'Q_G_3_0_8', 'Q_G_3_0_9', 'Q_G_3_1_0', 'Q_B_2_0_0', 'Q_B_2_0_1',\n",
    "          'Q_B_2_0_2', 'Q_B_2_0_3', 'Q_B_2_0_4', 'Q_B_2_0_5', 'Q_B_2_0_6', 'Q_B_2_0_7', 'Q_B_2_0_8', 'Q_B_2_0_9',\n",
    "          'Q_B_2_1_0', 'Q_NIR_8_0_0', 'Q_NIR_8_0_1', 'Q_NIR_8_0_2', 'Q_NIR_8_0_3', 'Q_NIR_8_0_4', 'Q_NIR_8_0_5', \n",
    "          'Q_NIR_8_0_6', 'Q_NIR_8_0_7', 'Q_NIR_8_0_8', 'Q_NIR_8_0_9', 'Q_NIR_8_1_0']\n",
    "geom = ['AREA', 'GEOM_R1', 'GEOM_R2', 'GEOM_R3', 'GEOM_R4']\n",
    "others = ['CONTRUCTIONYEAR', 'MAXBUILDINGFLOOR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "#### <font color=\"#004D7F\">3.1.1 Variables relativas al Geoposicionamiento</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información de longitud-latitud relativa a las variables **X** e **Y** ha sido escalada y desplazada aleatoriamente (manteniendo la relación con el resto de registros). Aún así vamos a intentar dibujar las geolocalizaciones que tenemos en el conjunto de datos con respecto a la latitud y la longitud para hacernos una idea de las parcelas y de la clase que presentan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[geoposition].isna().sum()[df_modelar[geoposition].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no presenta valores perdidos y por lo tanto no es realizar ningun tipo preprocesamiento a estas variables.\n",
    " \n",
    "A continuación vamos a mostrar todas las geoposiciones de todo el conjunto de datos para hacernos una idea de la localización, la dispersión de los valores y ver si podemos discriminar por zonas, o incluso agrupar para poder hacer una primera aproximación de modelo supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "sns.scatterplot(x=\"X\", y=\"Y\", hue=\"CLASE\",data=df_modelar)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos previamente al predominar registros cuya clase es `Residential`, se ve reflejado perfectamente en el mapa proyectado, situandose la mayor parte de registros en la parte central, mientras que clases como `Agriculture` o `Industrial` se sitúan en zonas de extrarradio de la ciudad de Madrid.\n",
    "Sin embargo, el resto de clases se encuentran mezcladas, o es más complejo discriminar con la clase predominante, lo cual presenta sentido, ya que las tiendas o los lugares públicos no se suelen situar en zonas de extrarradio, salvo en casos excepcionales.\n",
    "\n",
    "Así mismo, vamos a analizar cada una de las clases con respecto a la geolocalización de los registros, con el objetivo de abstraernos del resto de clases y que no nos afecte la clase predominante a la hora de graficar para ver que información nos pueden trasmitir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"X\", y=\"Y\", col=\"CLASE\", hue=\"CLASE\", kind=\"scatter\", col_wrap=3, data=df_modelar);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos comentado previamente, podemos observar que los registros pertenecientes a la clase de `Agricultura` se encuentran en zonas de extrarradio, mientras que el resto de registros están mas céntricos. Por otro lado se pueden ver pequeñas zonas o agrupaciones de registros, que probablemente con algun tipo de modelo de clasificación mediante *clusters* se podrían clasificar correctamente u obtener un buen rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section312\"></a>\n",
    "#### <font color=\"#004D7F\">3.1.2 Variables relativas a los Colores</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables referentes a los colores se corresponden a información obtenida de laa imágenes proporcionadas por el satélite Sentinel II del servicio Copernicus de la Agencia Espacial Europea.\n",
    "Las imágenes satelitales se han tratado y se ha extraído información de 4 canales (R, G, B y NIR), correspondientes a las bandas de color rojo, verde y azul, y el infrarrojo cercano.\n",
    "El valor mostrado en cada una de estas variables corresponde a la intensidad por deciles en cada imagen.\n",
    "\n",
    "La banda de color `rojo` corresponde a la banda 4 del espectro visible, el `verde` a la banda 3 y el `azul` a la banda 2, mientras que el `infrarrojo cercano` hace referencia a la banda 8 del espectro electromagnético. Dichas bandas junto con el valor de su longitud de onda central se puede observar en la siguiente imagen. Además, todas ellas presentan una resolución de **10m/px**.\n",
    "\n",
    "Con las bandas 8-4-3 podemos ver la vegetación en tonos rojos, las zonas urbanas son de color azul cian, y los suelos varían de marrón oscuro (también zonas quemadas) a marrón claro. El hielo, la nieve y las nubes son blancos o cian claro. Esta es una combinación de banda muy popular y es útil para estudios de vegetación, monitoreo de drenaje y patrones de suelo y varias etapas de crecimiento de cultivos. En general, los tonos rojos intensos indican hojas anchas y/o vegetación más sana, mientras que los rojos más claros significan pastizales o áreas escasamente vegetadas. Las áreas urbanas densamente pobladas se muestran en azul claro. Esta combinación de bandas ofrece resultados similares a la fotografía aérea infrarroja tradicional.\n",
    "\n",
    "Para más información con respecto al Satelite Sentinel II y sus propiedades: https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/sentinel_resolution.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a las variables que presenta el conjunto de datos, todas empiezan con la letra **Q** seguidas del color siendo R, G, B o NIR, seguidamente el número de la banda que corresponde a cada uno de los colores siendo estos: 4, 3, 2 y 8, y finalmente, disponemos de 11 registros por cada una de las bandas, ya que tenemos valores desde el 0 al 10.\n",
    "\n",
    "Por ejemplo de la banda roja tenemos del Q_R_4_0_0 al Q_R_4_1_0, teniendo entre medias todas las variables referentes a la banda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos. En este caso no presenta valores perdidos y por lo tanto no es realizar ningun tipo de análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[colors].isna().sum()[df_modelar[colors].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar[colors].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estudiar la correlación de todas y cada una de las variables relacionadas con el color es inviable y no se observarían correctamente los datos, lo que haremos es un agrupamiento por colores, es decir, tendremos lo siguiente:\n",
    "\n",
    "- **Rojo**\n",
    "- **Verde**\n",
    "- **Azul**\n",
    "- **NIR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color rojo\n",
    "df_modelar[colors[:11]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el color rojo podemos observar que existe una gran correlación entre casi todas las variables, excepto con las pertenecientes al decil 0 y 10. Por otro lado se puede observar que cada una de ellas presenta una mayor correlación con su respectivo antecesor y sucesor. Por ejemplo, la variable *Q_R_4_0_5* presenta una mayor correlación con *Q_R_4_0_4* y *Q_R_4_0_6*\n",
    "\n",
    "Como excepción, decir que el decil 9 (*Q_R_4_0_9*) presenta una mayor correlación con sus dos antecesores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color verde\n",
    "df_modelar[colors[11:22]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del color verde ocurre exactamente lo mismo que para el color rojo, ya que la máxima correlación la presentan con su decil anterior y posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color azul\n",
    "df_modelar[colors[22:33]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocurre lo mismo con el color azul y también para el NIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación perteneciente al color azul\n",
    "df_modelar[colors[33:44]].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de ver y comprobar la correlación que presentan este tipo de variables, también se ha realizado un pequeño análisis para comprender qué representan realmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colors = [df_modelar.columns[2:13], df_modelar.columns[13:24], df_modelar.columns[24:35], df_modelar.columns[35:46]]\n",
    "colors = [ 'red', 'green', 'blue', 'gray']\n",
    "for idx, val in enumerate(list_colors):\n",
    "    plt.figure(idx, figsize=(16,2))\n",
    "    sns.barplot(x=df_modelar.iloc[1][val].index, y=df_modelar.iloc[1][val].values, color=colors[idx], label=colors[idx])\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FALTA EXPLICACION DE LA SUMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = df_modelar[df_modelar.columns[2:-42]]\n",
    "df_green = df_modelar[df_modelar.columns[13:-31]]\n",
    "df_blue = df_modelar[df_modelar.columns[24:-20]]\n",
    "df_nir = df_modelar[df_modelar.columns[35:-9]]\n",
    "\n",
    "df_sum = df_red.sum(axis=1) + df_green.sum(axis=1) + df_blue.sum(axis=1) + df_nir.sum(axis=1)\n",
    "df_sum.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta gráfica podemos ver que los valores van creciendo progresivamente en función del decil en el cual se encuentran, por lo que descartamos que se trate de un histograma. Además, en el caso de ser un histograma, el valor total de la suma de las diferentes variables correspondientes a los colores debería de ser igual para cada uno de los distintos registros, ya que han sido extraidos de una misma imagen del satélite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section313\"></a>\n",
    "#### <font color=\"#004D7F\">3.1.3 Variables relativas a la Geometría</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a estas variables no tenemos demasiada información, lo único que sabemos es que las métricas geométricas se encuentran generadas automáticamente, bajo el prefijo **GEOM** y la variable **AREA** que corresponde a los metros cuadrados de la parcela a clasificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presenta o no valores perdidos. En este caso no presenta valores perdidos y por lo tanto no es realizar ningun tipo de análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modelar[geom].isna().sum()[df_modelar[geom].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[geom].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos observar que existe una gran diferencia entre los valores máximos y mínimos, por lo que vamos a mostrar diagrama de cajas para observar esta varianza y comprobar si es correcta.\n",
    "En el siguiente diagrama de cajas observamos que los datos se encuentran demasiado alejados de la media y la mediana, por lo tanto, creemos que podrían ser **outliers**, y sería conveniente realizar un estudio más en profundidad para que en el caso de que sean outliers, decidir si se eliminan o no, ya que pueden aportar ruido al modelo cuando éste sea entrenado con el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for col, ax in enumerate(axs.flatten()):\n",
    "    col_name = geom[col]\n",
    "    sns.boxplot(x=df_modelar[col_name], orient='vertical', ax=ax)\n",
    "    ax.set_title(col_name);    \n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_outliers_geom(df, columns):\n",
    "    df_aux = df.copy()\n",
    "    for col_name in columns:\n",
    "        if col_name == 'AREA':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.8)\n",
    "            df_aux = df_aux[df_aux[col_name] < third_quantile_area]\n",
    "        elif col_name == 'GEOM_R1':\n",
    "            first_quantile_area = df_aux[col_name].quantile(0.016)\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.92)\n",
    "            df_aux = df_aux[(df_aux[col_name] > first_quantile_area) & (df_aux[col_name] < third_quantile_area)]\n",
    "        elif col_name == 'GEOM_R2':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.96)\n",
    "            df_aux = df_aux[df_aux[col_name] < third_quantile_area]\n",
    "        elif col_name == 'GEOM_R3':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.96)\n",
    "            df_aux = df_aux[df_aux[col_name] < third_quantile_area]\n",
    "        elif col_name == 'GEOM_R4':\n",
    "            third_quantile_area = df_aux[col_name].quantile(0.93)\n",
    "            first_quantile_area = df_aux[col_name].quantile(0.005)\n",
    "            df_aux = df_aux[(df_aux[col_name] > first_quantile_area) & (df_aux[col_name] < third_quantile_area)]\n",
    "        \n",
    "    return df_aux\n",
    "df_aux = delete_outliers_geom(df_modelar, geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de aplicar una eliminación de los supuestos outliers obtenemos el siguiente diagrama de cajas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for col, ax in enumerate(axs.flatten()):\n",
    "    col_name = geom[col]\n",
    "    sns.boxplot(x=df_aux[col_name], orient='vertical', ax=ax)\n",
    "    ax.set_title(col_name);    \n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset con outliers: {df_modelar.shape}\")\n",
    "print(f\"Dataset sin outliers: {df_aux.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,4))\n",
    "sns.countplot(x='CLASE', data=df_modelar, order=list_class_order, ax=ax1)\n",
    "ax1.set_title('Distribución de muestras con outliers')\n",
    "sns.countplot(x='CLASE', data=df_aux, order=list_class_order, ax=ax2);\n",
    "ax2.set_title('Distribución de muestras sin outliers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La eliminación de outliers reduce considerablemente el número de registros de nuestro conjunto de datos y es por ello por lo que debemos de valorar si se deben de eliminar o no estos outliers o si realmente se trata de outliers o no. \n",
    "\n",
    "Aún así, si comprobamos la correlación de este conjunto de variables, con y sin outliers podemos observar que el hecho de eliminar tantos registros nos mejora apenas la correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with_outliers = df_modelar.corr()[geom]\n",
    "with_outliers.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "without_outliers = df_aux.corr()[geom]\n",
    "without_outliers.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables geométricas parecen tener una gran importancia en nuestro conjunto de datos, por lo que es conveniente seguir realizando un análisis exahustivo de ellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del área media por cada una de las clases a predecir\n",
    "df_modelar.groupby('CLASE')['AREA'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "sns.barplot(x=df_modelar.groupby('CLASE')['AREA'].mean().index.values, y=df_modelar.groupby('CLASE')['AREA'].mean().values, order=list_class_order)\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Media del área')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico se puede observar como la variable `RESIDENTIAL` que es la mayoritaría en nuestro conjunto de datos, presenta un área media menor en comparación con el resto de clases a clasificar. Esto nos puede dar una idea del tamaño de cada uno de los terrenos clasificados como `RESIDENTIAL` y se puede comprobar que representan un menor tamaño que el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar.groupby('CONTRUCTIONYEAR')[['AREA']].mean().nlargest(10, 'AREA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "sns.lineplot(data=df_modelar.groupby('CONTRUCTIONYEAR')[['AREA']].mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta gráfica se aprecia un pequeño aumento de la media del área conforme avanzan los años y llegamos a la actualidad o a los datos más reciente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section314\"></a>\n",
    "#### <font color=\"#004D7F\">Variables relativas al año de construcción y máximo de pisos de los edificios colindantes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente comprobamos si presentan o no valores perdidos. En este caso si presenta valores perdidos y por lo tanto es conveniente realizar un análisis extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_modelar[others].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora realizamos una comprobación del conjunto de datos completo podemos observar que hay otra variable discreta que también presenta valores perdidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar.isna().sum()[df_modelar.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar[df_modelar.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en realidad estos 40 valores perdidos corresponden unicamente con 20 registros de nuestro conjunto de datos, ya que casualmente los valores perdidos se presentan de forma simultánea tanto en la variable `CONTRUCTIONYEAR` como `MAXBUILDINGFLOOR`. Dado los valores perdidos pertenecen a las clases más desbalanceadas de nuestro conjunto se debe de tomar la decisión de qué hacer con los valores perdidos. \n",
    "\n",
    "También se debe de tener en cuenta que la variable `CONTRUCTIONYEAR` tiene un orden que indica la calidad del terreno, por lo que no podríamos establecer cualquier valor. Esta decisión se resolverá más adelante.\n",
    "\n",
    "Como información adicional, se realiza una gráfica interactiva para visualizar el número de registros de cada clase en función del año de construcción de los edificios colindantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year_class(Year=2017):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.countplot(df_modelar[df_modelar['CONTRUCTIONYEAR']==Year]['CONTRUCTIONYEAR'], hue=df_modelar['CLASE'])\n",
    "    plt.ylabel('Number')\n",
    "    plt.show()\n",
    "    print(f'-----------Year {Year}---------')\n",
    "    print(df_modelar[df_modelar['CONTRUCTIONYEAR']==Year]['CLASE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_year_class,\n",
    "         Year = np.sort(df_modelar['CONTRUCTIONYEAR'].unique()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_year = df_modelar.groupby('CONTRUCTIONYEAR')['CLASE'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "df_group_year.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos centramos en aquellas clases que son menos predominantes, ya que como el problema está desbalanceado, la clase Residencial es predominante.\n",
    "En la siguiente gráfica observamos que entre los años 1925 y 2017 los edificios predominantes son aquellos que presentan la clase industrial y publica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df_group_year.columns.tolist()[0:-2]\n",
    "classes.append('RETAIL')\n",
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "df_group_year[classes].plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falta maxbuldingfloor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "### <font color=\"#004D7F\">3.2 Tratamiento de las columnas discretas </font>\n",
    "\n",
    "\n",
    "En relación a estas columnas, dos aspectos muy relevantes de cara a la construcción de un modelo con `scikit-learn` son: el número de valores que puede tomar cada una; y si existe una relación de orden entre estos valores. Estos factores determinan el tipo de transformación que se ha de hacer. Existen cuatro posibilidades:\n",
    "\n",
    "* Cuando la columna toma dos valores, se puede binarizar y convertir a numérica diréctamente. \n",
    "* Si el tamaño del conjunto de valores es mayor que dos, y no existe una relación de orden entre ellos, se aplica `One Hot Encoding` (se aplicará posteriormente en el `Pipeline` de transformaciones).\n",
    "* Si existe una relación de orden, los valores se transforman a numéricos, sustituyendo cada valor por su orden. \n",
    "* Si el conjunto de valores extremadamente grande se ha de explorar, ya que es muy posible que se trate de un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordar que la variable CLASE también es discreta pero se ha eliminado al ser la varible objetivo\n",
    "num_values_dis_df_col = [(col, len(df_modelar[col].value_counts())) for col in dis_df_columns]\n",
    "num_values_dis_df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta variable en concreto tenemos una información adicional y es que se trata de una variable categórica representativa de la calidad y que tiene un órden:\n",
    "\n",
    "<b>MAYOR a MENOR CALIDAD: A > B > C > 1 > 2 > 3 >...> 8 > 9</b>\n",
    "\n",
    "Por lo tanto, lo primero que debemos de hacer es establecer ese órden en estas variable en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ¿Tratamos aqui ya los valores perdidos o sigo poniendo nan?\n",
    "def process_cadastralquality(value):\n",
    "    dic = {'A': 11, 'B': 10, 'C': 9}\n",
    "    if value in dic:\n",
    "        return dic[value]\n",
    "    else:\n",
    "        try:\n",
    "            return 9 - int(value)\n",
    "        except ValueError:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar['CADASTRALQUALITYID'] = df_modelar['CADASTRALQUALITYID'].apply(process_cadastralquality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelar['CADASTRALQUALITYID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=df_modelar['CADASTRALQUALITYID'], data=df_modelar, hue=\"CLASE\", dodge=False)\n",
    "plt.title('Distribución de muestras');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
